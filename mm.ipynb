{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "# from torchsummary import summary\r\n",
    "import torch.nn as nn\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g 512,512\r\n",
    "\r\n",
    "class Downsample_1(nn.Module):\r\n",
    "    def __init__(self,\r\n",
    "                 in_channels,\r\n",
    "                 out_channels=32,\r\n",
    "                #  internal_ratio=4,\r\n",
    "                 kernel_size=3,\r\n",
    "                 padding=0,\r\n",
    "                 dropout_prob=0.,\r\n",
    "                 stride = 2,\r\n",
    "                 bias=False,\r\n",
    "                 relu=True):\r\n",
    "        super(Downsample_1,self).__init__()\r\n",
    "\r\n",
    "\r\n",
    "        if relu:\r\n",
    "            activation = nn.ReLU()\r\n",
    "        else:\r\n",
    "            activation = nn.PReLU()\r\n",
    "\r\n",
    "        self.conv2d_d1 = nn.Conv2d(in_channels=in_channels, out_channels=11,kernel_size=kernel_size, stride=stride, padding=padding, bias=bias, dilation=1)\r\n",
    "        self.conv2d_d2 = nn.Conv2d(in_channels=in_channels, out_channels=9,kernel_size=kernel_size, stride=stride, padding=1, bias=bias, dilation=2)\r\n",
    "        self.conv2d_d5 = nn.Conv2d(in_channels=in_channels, out_channels=9,kernel_size=kernel_size, stride=stride, padding=4, bias=bias, dilation=5)\r\n",
    "        self.ext_branch = nn.MaxPool2d(kernel_size, stride=2, padding=padding)\r\n",
    "        # self.half = nn.MaxPool2d(2, stride=2)\r\n",
    "        self.activation = activation\r\n",
    "        self.batch_norm = nn.BatchNorm2d(out_channels)\r\n",
    "\r\n",
    "    def forward(self, input):\r\n",
    "        print(input.shape)\r\n",
    "        main1_d1= self.conv2d_d1(input)\r\n",
    "        print(main1_d1.shape)\r\n",
    "        main2_d2 = self.conv2d_d2(input)\r\n",
    "        print(main2_d2.shape)\r\n",
    "        main3_d5 = self.conv2d_d5(input)\r\n",
    "        print(main3_d5.shape)\r\n",
    "        # ext1=self.half(input)\r\n",
    "        ext1 = self.ext_branch(input)\r\n",
    "        print(ext1.shape)\r\n",
    "        \r\n",
    "        \r\n",
    "        \r\n",
    "        out = torch.cat((main1_d1,main2_d2,main3_d5,ext1), dim=1)\r\n",
    "        print('out after concate', out.shape)\r\n",
    "        out = self.batch_norm(out)\r\n",
    "        out = self.activation(out)\r\n",
    "        print('final', out)\r\n",
    "\r\n",
    "\r\n",
    "        return out\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Downsample_1(in_channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 360, 640])\n",
      "torch.Size([1, 11, 179, 319])\n",
      "torch.Size([1, 9, 179, 319])\n",
      "torch.Size([1, 9, 179, 319])\n",
      "torch.Size([1, 3, 179, 319])\n",
      "out after concate torch.Size([1, 32, 179, 319])\n",
      "final tensor([[[[0.3398, 0.9345, 0.4279,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.1441, 0.0000, 3.0844,  ..., 0.6179, 0.0000, 0.0607],\n",
      "          [0.0000, 1.6749, 0.1517,  ..., 0.0000, 0.0000, 0.2969],\n",
      "          ...,\n",
      "          [0.0291, 0.0000, 0.6921,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9656, 0.0000,  ..., 0.0000, 1.2891, 0.0000],\n",
      "          [0.5429, 0.0000, 0.7381,  ..., 0.2990, 0.3699, 0.3983]],\n",
      "\n",
      "         [[0.3781, 0.0000, 0.0000,  ..., 0.0959, 0.0000, 0.0000],\n",
      "          [1.4096, 0.9007, 0.0000,  ..., 0.0000, 0.4538, 0.0000],\n",
      "          [0.0000, 0.0000, 2.2600,  ..., 0.2458, 0.0000, 1.0428],\n",
      "          ...,\n",
      "          [0.0000, 0.1881, 0.3792,  ..., 0.7491, 0.5357, 0.3237],\n",
      "          [0.3144, 0.0000, 0.7905,  ..., 0.1107, 0.6475, 0.0000],\n",
      "          [0.0000, 0.0000, 0.3101,  ..., 0.0970, 0.0072, 0.0000]],\n",
      "\n",
      "         [[0.1438, 0.7549, 0.0000,  ..., 2.1146, 0.6793, 0.0000],\n",
      "          [0.0000, 0.8661, 0.0000,  ..., 0.0610, 0.0000, 1.0383],\n",
      "          [0.0000, 0.0000, 1.3411,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [1.6372, 0.1292, 0.0000,  ..., 1.1426, 1.1326, 0.0000],\n",
      "          [0.0000, 0.9303, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.2550, 0.0000, 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000, 0.5692, 0.0000,  ..., 1.6937, 1.6937, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 2.0511, 2.0511],\n",
      "          [1.0981, 0.0000, 0.0000,  ..., 0.0000, 0.7731, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.5262, 0.0000, 0.1075],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 1.1649, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0336, 1.6015,  ..., 0.0000, 0.5041, 0.5041],\n",
      "          [1.5652, 0.0000, 0.0000,  ..., 0.0000, 0.5041, 0.9909],\n",
      "          ...,\n",
      "          [0.0727, 0.0000, 0.0000,  ..., 2.2301, 2.2301, 0.0000],\n",
      "          [0.0000, 1.1485, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0274, 0.0000, 0.4161,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.4943, 1.4943, 0.0452,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [1.4943, 1.4943, 1.5695,  ..., 0.7659, 0.7659, 0.0000],\n",
      "          [0.0000, 0.0000, 0.5271,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.9507, 0.0000, 0.0000]]]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.3398, 0.9345, 0.4279,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.1441, 0.0000, 3.0844,  ..., 0.6179, 0.0000, 0.0607],\n",
       "          [0.0000, 1.6749, 0.1517,  ..., 0.0000, 0.0000, 0.2969],\n",
       "          ...,\n",
       "          [0.0291, 0.0000, 0.6921,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.9656, 0.0000,  ..., 0.0000, 1.2891, 0.0000],\n",
       "          [0.5429, 0.0000, 0.7381,  ..., 0.2990, 0.3699, 0.3983]],\n",
       "\n",
       "         [[0.3781, 0.0000, 0.0000,  ..., 0.0959, 0.0000, 0.0000],\n",
       "          [1.4096, 0.9007, 0.0000,  ..., 0.0000, 0.4538, 0.0000],\n",
       "          [0.0000, 0.0000, 2.2600,  ..., 0.2458, 0.0000, 1.0428],\n",
       "          ...,\n",
       "          [0.0000, 0.1881, 0.3792,  ..., 0.7491, 0.5357, 0.3237],\n",
       "          [0.3144, 0.0000, 0.7905,  ..., 0.1107, 0.6475, 0.0000],\n",
       "          [0.0000, 0.0000, 0.3101,  ..., 0.0970, 0.0072, 0.0000]],\n",
       "\n",
       "         [[0.1438, 0.7549, 0.0000,  ..., 2.1146, 0.6793, 0.0000],\n",
       "          [0.0000, 0.8661, 0.0000,  ..., 0.0610, 0.0000, 1.0383],\n",
       "          [0.0000, 0.0000, 1.3411,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [1.6372, 0.1292, 0.0000,  ..., 1.1426, 1.1326, 0.0000],\n",
       "          [0.0000, 0.9303, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.2550, 0.0000, 0.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000, 0.5692, 0.0000,  ..., 1.6937, 1.6937, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 2.0511, 2.0511],\n",
       "          [1.0981, 0.0000, 0.0000,  ..., 0.0000, 0.7731, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.5262, 0.0000, 0.1075],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 1.1649, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0336, 1.6015,  ..., 0.0000, 0.5041, 0.5041],\n",
       "          [1.5652, 0.0000, 0.0000,  ..., 0.0000, 0.5041, 0.9909],\n",
       "          ...,\n",
       "          [0.0727, 0.0000, 0.0000,  ..., 2.2301, 2.2301, 0.0000],\n",
       "          [0.0000, 1.1485, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0274, 0.0000, 0.4161,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[1.4943, 1.4943, 0.0452,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [1.4943, 1.4943, 1.5695,  ..., 0.7659, 0.7659, 0.0000],\n",
       "          [0.0000, 0.0000, 0.5271,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.9507, 0.0000, 0.0000]]]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1,3, 360, 640)\r\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsample_1(\n",
      "  (conv2d_d1): Conv2d(3, 11, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "  (conv2d_d2): Conv2d(3, 9, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(2, 2), bias=False)\n",
      "  (conv2d_d5): Conv2d(3, 9, kernel_size=(3, 3), stride=(2, 2), padding=(4, 4), dilation=(5, 5), bias=False)\n",
      "  (ext_branch): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (activation): ReLU()\n",
      "  (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regular(nn.Module):\r\n",
    "    def __init__(self,\r\n",
    "                 in_channels,\r\n",
    "                 out_channels=32,\r\n",
    "                #  internal_ratio=4,\r\n",
    "                 kernel_size=3,\r\n",
    "                 padding=0,\r\n",
    "                 dropout_prob=0.,\r\n",
    "                 stride = 2,\r\n",
    "                 bias=False,\r\n",
    "                 relu=True):\r\n",
    "        super(Regular,self).__init__()\r\n",
    "\r\n",
    "\r\n",
    "        if relu:\r\n",
    "            activation = nn.ReLU()\r\n",
    "        else:\r\n",
    "            activation = nn.PReLU()\r\n",
    "\r\n",
    "        self.conv2d_d1 = nn.Conv2d(in_channels=in_channels, out_channels=11,kernel_size=kernel_size, stride=stride, padding=padding, bias=bias, dilation=1)\r\n",
    "        self.conv2d_d2 = nn.Conv2d(in_channels=in_channels, out_channels=9,kernel_size=kernel_size, stride=stride, padding=1, bias=bias, dilation=2)\r\n",
    "        self.conv2d_d5 = nn.Conv2d(in_channels=in_channels, out_channels=9,kernel_size=kernel_size, stride=stride, padding=4, bias=bias, dilation=5)\r\n",
    "        self.ext_branch = nn.MaxPool2d(kernel_size, stride=2, padding=padding)\r\n",
    "        # self.half = nn.MaxPool2d(2, stride=2)\r\n",
    "        self.activation = activation\r\n",
    "        self.batch_norm = nn.BatchNorm2d(out_channels)\r\n",
    "\r\n",
    "    def forward(self, input):\r\n",
    "        print(input.shape)\r\n",
    "        main1_d1= self.conv2d_d1(input)\r\n",
    "        print(main1_d1.shape)\r\n",
    "        main2_d2 = self.conv2d_d2(input)\r\n",
    "        print(main2_d2.shape)\r\n",
    "        main3_d5 = self.conv2d_d5(input)\r\n",
    "        print(main3_d5.shape)\r\n",
    "        # ext1=self.half(input)\r\n",
    "        ext1 = self.ext_branch(input)\r\n",
    "        print(ext1.shape)\r\n",
    "        \r\n",
    "        \r\n",
    "        \r\n",
    "        out = torch.cat((main1_d1,main2_d2,main3_d5,ext1), dim=1)\r\n",
    "        print('out after concate', out.shape)\r\n",
    "        out = self.batch_norm(out)\r\n",
    "        out = self.activation(out)\r\n",
    "        print('final', out)\r\n",
    "\r\n",
    "\r\n",
    "        return out\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a48b01b56eccf21866b656d691e7a6d227bd9cd6c49ca5cde9f5de391096b96f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('torch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}